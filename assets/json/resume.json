{
  "basics": {
    "name": "Xiuqi Zhu",
    "label": "MS in Information Science @ CMU",
    "image": "assets/img/prof_pic.jpg",
    "email": "xiuqizhu@andrew.cmu.edu",
    "phone": "+86 159 2655 6807",
    "summary": "Master's student at CMU. Focus on deep learning, generative AI, and efficient LLM systems. Interned at Qunar and Shanghai Petroleum & Natural Gas Exchange.",
    "location": {
      "city": "Pittsburgh",
      "region": "PA",
      "countryCode": "US"
    },
    "profiles": [
      { "network": "GitHub", "username": "xiuqi-zhu", "url": "https://github.com/xiuqi-zhu" },
      { "network": "LinkedIn", "username": "xiuqizhu", "url": "https://www.linkedin.com/in/xiuqizhu/" }
    ]
  },
  "work": [
    {
      "name": "Carnegie Mellon University",
      "position": "Research Assistant (Advisor: Prof. Virginia Smith)",
      "location": "Pittsburgh, PA",
      "startDate": "2025-08",
      "endDate": "Present",
      "summary": "Dynamic LoRA for efficient LLM training (target NeurIPS 2026).",
      "highlights": [
        "DFLoRA: gradient-norm–based switching; +2.1% vs static LoRA.",
        "MoE-inspired routing; 42% less catastrophic forgetting vs full fine-tuning.",
        "Qwen2.5 & Gemma 3 across 10+ tasks."
      ]
    },
    {
      "name": "Qunar (去哪儿旅行)",
      "position": "Algorithm Intern (User Growth)",
      "location": "Beijing, China",
      "startDate": "2024-10",
      "endDate": "2025-03",
      "summary": "Multi-agent RAG pipelines and multi-modal prediction for travel ads.",
      "highlights": [
        "LangGraph multi-agent; RAG over travel KB; 60% throughput gain.",
        "MMoE model (ViT, BERT, CLIP); +8% CTR, +2% ROI in A/B tests.",
        "300k+ query–POI pipeline; 97.5% retention-set accuracy."
      ]
    },
    {
      "name": "Shanghai Petroleum and Natural Gas Exchange",
      "position": "Machine Learning Algorithm Intern",
      "location": "Shanghai, China",
      "startDate": "2024-07",
      "endDate": "2024-09",
      "summary": "ETL pipelines and volatility-aware pricing models.",
      "highlights": [
        "API-based ETL (Aliyun → Hadoop); 10k+ records/day; 35% shorter E2E.",
        "XGBoost pricing with market indices; MAPE −8%."
      ]
    }
  ],
  "education": [
    {
      "institution": "Carnegie Mellon University",
      "location": "Pittsburgh, PA, USA",
      "url": "https://www.cmu.edu/",
      "area": "Information Science",
      "studyType": "MS",
      "startDate": "2025-08",
      "endDate": "2026-12",
      "score": "3.7/4.0",
      "courses": ["Deep Learning", "Generative AI", "LLM Systems", "Deep RL", "NLP"]
    },
    {
      "institution": "Central University of Finance and Economics",
      "location": "Beijing, China",
      "url": "https://en.cufe.edu.cn/",
      "area": "Data Science",
      "studyType": "B.S.",
      "startDate": "2021-09",
      "endDate": "2025-06",
      "score": "3.8/4.0",
      "courses": ["Data Structures", "Machine Learning", "Statistical Modeling", "Distributed Big Data", "Database Systems"]
    }
  ],
  "skills": [
    { "name": "Programming", "level": "Proficient", "keywords": ["Python", "C++", "SQL", "Java", "Scala", "R", "Bash"] },
    { "name": "AI & ML", "level": "Proficient", "keywords": ["PyTorch", "TensorFlow", "Scikit-learn", "Hugging Face", "LangChain", "RAG", "Deep Learning"] },
    { "name": "Cloud & Tools", "level": "Familiar", "keywords": ["Docker", "Git", "Kafka", "Spark", "Hadoop", "AWS", "Kubernetes", "FastAPI"] }
  ],
  "languages": [
    { "language": "Chinese", "fluency": "Native" },
    { "language": "English", "fluency": "Fluent" }
  ],
  "publications": [
    {
      "name": "Multimodal Emotion Recognition Improvement Based on Stacking Ensemble Learning",
      "publisher": "ADMA 2025",
      "releaseDate": "2026",
      "summary": "Stacking ensemble for multimodal emotion recognition."
    }
  ],
  "projects": [
    {
      "name": "Dynamic LoRA for Efficient LLM Training",
      "summary": "Gradient-norm–based switching; MoE-inspired routing. Target NeurIPS 2026.",
      "highlights": ["DFLoRA framework", "Qwen2.5 & Gemma 3 benchmarks"],
      "startDate": "2025-08",
      "endDate": "Present"
    },
    {
      "name": "Transformer-based Speech Recognition (Kaggle Top 10%)",
      "summary": "Progressive training, CTC+CE, shallow fusion. 10.5% CER on test set.",
      "highlights": ["Progressive training", "10.5% CER"],
      "startDate": "2025-09",
      "endDate": "2025-12"
    }
  ]
}
